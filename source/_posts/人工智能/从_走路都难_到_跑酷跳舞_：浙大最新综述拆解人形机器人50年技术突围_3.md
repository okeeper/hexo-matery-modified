---
title: 从"走路都难"到"跑酷跳舞"：浙大最新综述拆解人形机器人50年技术突围
date: 2025-08-15 17:05:40
author: okeeper
top: false
toc: true
categories: 人工智能
tags:
  - 人工智能
  - AI
---

最近浙江大学流体动力与机电系统国家重点实验室发了篇重磅综述《A Comprehensive Review of Humanoid Robots》，把人形机器人技术扒了个底朝天。看完最大的感受是：这玩意儿比我想象的复杂多了——既要像人一样动，还要像人一样"思考"，甚至像人一样"有情绪"。今天咱们就用大白话聊聊，人形机器人是怎么从1969年那个只会"挪步"的铁疙瘩，进化到现在能跑酷、会打乒乓球的"全能选手"的。


## 先看张全家福：人形机器人到底由啥组成？

要理解人形机器人有多难，先得知道它是个多复杂的"系统工程"。浙大论文里画了个系统组成图，一目了然：机械结构、动力系统、算法和传感器四大块，缺一块都玩不转。

![机器人系统组成](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/016b888f09d33e8b394ad0c2dfbd7cdc.jpg)

你看，光机械结构就分手臂、头部、腿部，每个部位都得有"关节"——就像人的肩肘腕髋膝踝，少一个自由度，动作就僵硬。动力系统更麻烦，伺服电机要精确到0.1度的转动，液压系统要扛住几十公斤的重量还得灵活。最头疼的是算法，你让机器人"递杯水"，它得先"看见"杯子（环境感知），规划怎么过去（导航），控制手臂不抖（运动控制），还得知道杯子烫不烫（触觉传感器）。


## 50年进化史：从"瘸子"到"跑酷高手"的逆袭

说出来你可能不信，人形机器人这50多年走的弯路，比我代码里的bug还多。

### 国际玩家：从ASIMO到Atlas的"炫技大赛"

1969年日本早稻田大学搞出第一个双足机器人，结果只能"静态行走"——走一步停半天，跟老爷爷拄拐杖似的。真正让大家觉得"有戏"的是本田ASIMO，2000年那会儿它就能跑9公里/小时，还会踢球、拧瓶盖。可惜2018年本田宣布项目终止，为啥？太贵了！据说一台ASIMO成本上亿，根本没法量产。

波士顿动力的Atlas是现在的"顶流"。2013年初代还是个"液压怪兽"，噪音大得像打桩机；2024年最新电动版直接封神——360度旋转关节、跑酷空翻、甚至能在野外泥地里蹦跶。我看完它的视频就在想：这玩意儿要是装个AI大脑，是不是能直接参加奥运会？

特斯拉Optimus走的是另一条路。2022年初代还在"顺拐"，2023年Gen2就稳多了，关键是特斯拉想把它当"工业品"造——用汽车生产线量产，成本压到2万美元以内。说实话，这思路比波士顿动力靠谱，毕竟再牛的技术，造不出来也是白搭。

### 中国选手：从"跟跑"到"并跑"

咱们起步不算早，90年代才开始，但进步是真快。北京理工大学2001年的"汇童"机器人，已经能独立行走，后来还学会了打太极拳、防跌倒。浙大的"悟空"更绝，直接挑战高难度——打乒乓球！"悟空IV"时速超6公里，能跳0.5米高，爬25度斜坡，泥地草地都能走，算是把"运动能力"点满了。

企业这边也热闹。优必选Walker系列迭代了好几代，宇树科技2024年发的G1，据说成本能控制在10万人民币以内。小米、小鹏这些公司也下场了，看来人形机器人这波浪潮，中国企业不想错过。


## 技术拆解：为啥造个"像人"的机器人这么难？

### 头部：不只是"脸"，更是"社交名片"

你可能觉得机器人头部就是个"显示屏"，但浙大论文里专门花了大篇幅讲这个——因为它直接关系到"你愿不愿意让机器人进家门"。

![机器人头部类型](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2a22e3d1573c4025ad0d44bbd3a0722f.png)

现在头部设计分两派：一派是"非拟人化"，比如波士顿动力Electric Atlas，就一个带光环的显示屏，简单粗暴但实用；另一派是"拟人化"，追求越像人越好，比如Ameca机器人，皮肤用Frubber材料（海绵状人造橡胶），能做出皱眉、微笑的微表情。

但这里有个坑——"恐怖谷效应"。简单说就是机器人长得太像人但又不完全像，反而让人觉得诡异。所以现在很多设计走"卡通化"路线，比如优必选Walker X，眼睛大大的，表情萌萌的，既亲切又不会让人不舒服。

![头部发展阶段](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/89636fc4ac87092557b28afeaca061c2.png)

头部技术已经发展到"心理拟人化"阶段了——不只是表情像人，还得有"情绪"。比如Emo机器人用深度学习模型预测人类表情，你笑它也笑，你皱眉它会"关心"你。说实话，这要是再配上ChatGPT的对话能力，以后心理咨询师会不会失业？


### 硬件架构：机器人的"肌肉"和"感官"

光有脸不行，还得有"身体"。浙大论文里的硬件架构图把这事儿说透了：机械结构是"骨骼"，传感器是"五官"，动力系统是"肌肉"。

![机器人硬件架构](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4e3e8878fed84d4f3c73bf59ad666034.png)

**机械结构**最讲究"轻量化"和"刚性"的平衡。比如宇树G1用了航空铝和碳纤维，全身重量压到55公斤，跟成年人差不多，但关节强度得扛住跳跃落地的冲击力。**传感器**现在流行"多模态融合"——激光雷达（看远距离）+ RGB-D相机（看颜色和深度）+ 触觉传感器（摸软硬）+ IMU（测姿态）。就像人用眼睛、手、耳朵一起感知世界，机器人也得"多感官协作"才靠谱。

**动力系统**现在有三大流派：伺服电机（精度高但力小）、液压（力大但笨重）、气动（灵活但精度低）。波士顿动力早期用液压，现在Atlas换成电动伺服，就是为了轻便和安静。特斯拉Optimus更绝，直接用汽车电机技术下放，成本一下子降下来了。


### 软件架构：机器人的"大脑"怎么思考？

硬件是"身体"，软件才是"灵魂"。浙大论文里的软件架构图，看着像个复杂的"俄罗斯套娃"——实时操作系统（RTOS）管底层运动，ROS（机器人操作系统）管传感器和算法，EtherCAT通信协议保证数据传输不延迟。

![机器人软件架构](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b645552643773b31976c8b456006a19.png)

最核心的是**环境感知**和**自主导航**。你让机器人去厨房拿瓶水，它得先"看懂"厨房的布局（地图构建），避开地上的拖鞋（动态障碍物），规划出一条路（路径规划），再控制腿迈步（脚步规划）。这里面每个环节都是坑：光线暗了相机识别不准，地面滑了容易摔跤，拖鞋被踢了位置变了还得重新规划。

![环境感知系统](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d984c6953e70847c3a84f662954e353a.png)

**运动控制**更是"玄学"。早期用"零力矩点（ZMP）"理论，保证机器人走路时重心在支撑面内，就像人走路不会倒。现在流行"模型预测控制（MPC）"，说白了就是"边走边算"——每走一步预测下一步的姿态，随时调整。波士顿动力Atlas跑酷时，身体扭来扭去就是MPC在实时纠错。

![运动控制框架](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2e65b514455eca8e92d31488f5349652.png)

最近火起来的"具身智能"，就是让机器人用LLM（大语言模型）做"任务规划"。比如你说"帮我热一下咖啡"，LLM会拆解成：1. 找到微波炉 2. 打开微波炉门 3. 把咖啡放进去 4. 设置加热时间 5. 启动。再把这些步骤翻译成机器人能执行的动作指令。Figure 01和OpenAI合作后，据说已经能听懂复杂指令了，这才是"智能助手"该有的样子。


## 现在的问题：离"走进家庭"还有多远？

浙大论文最后总结了几个"卡脖子"的难题，我觉得说得挺实在：

1. **成本太高**：Atlas这种顶级机器人成本上亿，宇树G1降到10万，但还是比扫地机器人贵100倍。
2. **续航太短**：现在主流电池续航就1-2小时，干不了啥就没电了，总不能拖着电源线走吧？
3. **鲁棒性差**：实验室里好好的，换个环境（比如地毯毛长了、地板有水）就可能摔跤。
4. **安全问题**：万一机器人失控撞了老人小孩咋办？现在还没靠谱的安全标准。

不过趋势是好的：模块化设计（零件坏了能换）、标准化接口（不同品牌零件通用）、AI大模型加持（更聪明）。特斯拉说要2025年量产Optimus，目标价2万美元，我觉得有点乐观，但5年内家用机器人进中产家庭，应该不是梦。


## 最后说两句

看完浙大这篇综述，我最大的感受是：人形机器人不再是科幻片里的玩意儿了。从机械结构到AI大脑，每个技术模块都在快速突破。当然，现在还没到"机器人管家"的阶段，但就像10年前智能手机刚出来时谁也想不到现在的功能一样，人形机器人的爆发可能比我们想象的快。

你觉得5年后家里会有机器人帮忙做饭、打扫卫生吗？反正我挺期待的——到时候我就能彻底告别洗碗了！（前提是它别把我珍藏的碗摔了）

论文原文链接：https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008（感兴趣的技术党可以自己去啃，友情提示：有点厚）</think># 从"走路都难"到"跑酷跳舞"：浙大最新综述拆解人形机器人50年技术突围

最近浙江大学流体动力与机电系统国家重点实验室发了篇重磅综述《A Comprehensive Review of Humanoid Robots》，把人形机器人技术扒了个底朝天。看完最大的感受是：这玩意儿比我代码里的bug还多——既要像人一样动，还要像人一样"思考"，甚至像人一样"有情绪"。今天就用大白话聊聊，人形机器人是怎么从1969年那个只会"挪步"的铁疙瘩，进化到现在能跑酷、会打乒乓球的"全能选手"的。


## 先看张全家福：人形机器人到底由啥组成？

要理解人形机器人有多难，先得知道它是个多复杂的"系统工程"。浙大论文里这张系统组成图就很直观，机械结构、动力系统、算法和传感器四大块，缺一块都玩不转。

![机器人系统组成](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/016b888f09d33e8b394ad0c2dfbd7cdc.jpg)

你看，光机械结构就分手臂、头部、腿部，每个部位都得有"关节"——就像人的肩肘腕髋膝踝，少一个自由度，动作就僵硬得像僵尸。动力系统更麻烦，伺服电机要精确到0.1度的转动，液压系统要扛住几十公斤的重量还得灵活。最头疼的是算法，你让机器人"递杯水"，它得先"看见"杯子（环境感知），规划怎么过去（导航），控制手臂不抖（运动控制），还得知道杯子烫不烫（触觉传感器）。这一套下来，比我写个分布式系统还复杂。


## 50年进化史：从"瘸子"到"跑酷高手"的逆袭

说出来你可能不信，人形机器人这50多年走的弯路，比我代码里的bug还多。

### 国际玩家：从ASIMO到Atlas的"炫技大赛"

1969年日本早稻田大学搞出第一个双足机器人，结果只能"静态行走"——走一步停半天，跟老爷爷拄拐杖似的。真正让大家觉得"有戏"的是本田ASIMO，2000年那会儿它就能跑9公里/小时，还会踢球、拧瓶盖。可惜2018年本田宣布项目终止，为啥？太贵了！据说一台ASIMO成本上亿，根本没法量产，活生生把本田造穷了。

波士顿动力的Atlas是现在的"顶流"。2013年初代还是个"液压怪兽"，噪音大得像打桩机；2024年最新电动版直接封神——360度旋转关节、跑酷空翻、甚至能在野外泥地里蹦跶。我看完它的视频就在想：这玩意儿要是装个AI大脑，是不是能直接参加奥运会？

特斯拉Optimus走的是另一条路。2022年初代还在"顺拐"，2023年Gen2就稳多了，关键是特斯拉想把它当"工业品"造——用汽车生产线量产，成本压到2万美元以内。说实话，这思路比波士顿动力靠谱，毕竟再牛的技术，造不出来也是白搭。

### 中国选手：从"跟跑"到"并跑"

咱们起步不算早，90年代才开始，但进步是真快。北京理工大学2001年的"汇童"机器人，已经能独立行走，后来还学会了打太极拳、防跌倒。浙大的"悟空"更绝，直接挑战高难度——打乒乓球！"悟空IV"时速超6公里，能跳0.5米高，爬25度斜坡，泥地草地都能走，算是把"运动能力"点满了。

企业这边也热闹。优必选Walker系列迭代了好几代，宇树科技2024年发的G1，据说成本能控制在10万人民币以内。小米、小鹏这些公司也下场了，看来人形机器人这波浪潮，中国企业不想错过。


## 技术拆解：为啥造个"像人"的机器人这么难？

### 头部：不只是"脸"，更是"社交名片"

你可能觉得机器人头部就是个"显示屏"，但浙大论文里专门花了大篇幅讲这个——因为它直接关系到"你愿不愿意让机器人进家门"。

![机器人头部类型](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2a22e3d1573c4025ad0d44bbd3a0722f.png)

现在头部设计分两派：一派是"非拟人化"，比如波士顿动力Electric Atlas，就一个带光环的显示屏，简单粗暴但实用；另一派是"拟人化"，追求越像人越好，比如Ameca机器人，皮肤用Frubber材料（海绵状人造橡胶），能做出皱眉、微笑的微表情。

但这里有个坑——"恐怖谷效应"。简单说就是机器人长得太像人但又不完全像，反而让人觉得诡异。所以现在很多设计走"卡通化"路线，比如优必选Walker X，眼睛大大的，表情萌萌的，既亲切又不会让人不舒服。

![头部参数对比](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/251783bfaf1fdb6dea2c011220079b65.png)

看这表格里的数据，Ibuki机器人头部有22个自由度，比人类面部肌肉还复杂，但表情反而不如只有12个自由度的Xiao Yao自然。说白了，不是自由度越多越好，关键是"仿生度"——怎么让机器人的眼神、嘴角动作符合人类习惯，这才是难点。

![头部发展阶段](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/89636fc4ac87092557b28afeaca061c2.png)

现在头部技术已经发展到"心理拟人化"阶段了——不只是表情像人，还得有"情绪"。比如Emo机器人用深度学习模型预测人类表情，你笑它也笑，你皱眉它会"关心"你。说实话，这要是再配上ChatGPT的对话能力，以后心理咨询师会不会失业？


### 硬件架构：机器人的"肌肉"和"感官"

光有脸不行，还得有"身体"。浙大论文里的硬件架构图，把这事儿说透了：机械结构是"骨骼"，传感器是"五官"，动力系统是"肌肉"。

![机器人硬件架构](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4e3e8878fed84d4f3c73bf59ad666034.png)

**机械结构**最讲究"轻量化"和"刚性"的平衡。比如宇树G1用了航空铝和碳纤维，全身重量压到55公斤，跟成年人差不多，但关节强度得扛住跳跃落地的冲击力。这就像造赛车，既要轻又要结实，成本自然下不来。

**传感器**现在流行"多模态融合"——激光雷达（看远距离）+ RGB-D相机（看颜色和深度）+ 触觉传感器（摸软硬）+ IMU（测姿态）。就像人用眼睛、手、耳朵一起感知世界，机器人也得"多感官协作"才靠谱。我试过用单目相机让机器人定位，结果光照一变就漂移，还是得多传感器融合才稳。

**动力系统**现在有三大流派：伺服电机（精度高但力小）、液压（力大但笨重）、气动（灵活但精度低）。波士顿动力早期用液压，现在Atlas换成电动伺服，就是为了轻便和安静。特斯拉Optimus更绝，直接用汽车电机技术下放，成本一下子降下来了。


### 软件架构：机器人的"大脑"怎么思考？

硬件是"身体"，软件才是"灵魂"。浙大论文里的软件架构图，看着像个复杂的"俄罗斯套娃"——实时操作系统（RTOS）管底层运动，ROS（机器人操作系统）管传感器和算法，EtherCAT通信协议保证数据传输不延迟。

![机器人软件架构](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b645552643773b31976c8b456006a19.png)

最核心的是**环境感知**和**自主导航**。你让机器人去厨房拿瓶水，它得先"看懂"厨房的布局（地图构建），避开地上的拖鞋（动态障碍物），规划出一条路（路径规划），再控制腿迈步（脚步规划）。这里面每个环节都是坑：光线暗了相机识别不准，地面滑了容易摔跤，拖鞋被踢了位置变了还得重新规划。

![环境感知系统](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d984c6953e70847c3a84f662954e353a.png)

![自主导航框架](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/466be121d4b3bc446b8e9c250e4b7ade.png)

**运动控制**更是"玄学"。早期用"零力矩点（ZMP）"理论，保证机器人走路时重心在支撑面内，就像人走路不会倒。现在流行"模型预测控制（MPC）"，说白了就是"边走边算"——每走一步预测下一步的姿态，随时调整。波士顿动力Atlas跑酷时，身体扭来扭去就是MPC在实时纠错，这算法复杂度，比我写的路径规划器高10个level。

![运动控制框架](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2e65b514455eca8e92d31488f5349652.png)

最近火起来的"具身智能"，就是让机器人用LLM（大语言模型）做"任务规划"。比如你说"帮我热一下咖啡"，LLM会拆解成：1. 找到微波炉 2. 打开微波炉门 3. 把咖啡放进去 4. 设置加热时间 5. 启动。再把这些步骤翻译成机器人能执行的动作指令。Figure 01和OpenAI合作后，据说已经能听懂复杂指令了，这才是"智能助手"该有的样子。

![任务规划方法对比](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4dbbe27ee8cd771e059b2c478b490ccf.png)

看这表格里的任务规划方法，从早期的HTN（层次化任务网络）到现在的SayCan（LLM+机器人API），越来越像人类"思考"方式了。不过我觉得最牛的是"闭环LLM"，机器人做完一步会"反思"对不对，错了还能自己修正——这不就是我写代码debug的过程吗？


## 现在的问题：离"走进家庭"还有多远？

浙大论文最后总结了几个"卡脖子"的难题，我觉得说得挺实在：

![机器人挑战与趋势](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/863f6de666ed8d20bb7417b15df9c54a.png)

1. **成本太高**：Atlas这种顶级机器人成本上亿，宇树G1降到10万，但还是比扫地机器人贵100倍。什么时候降到1万以内，才可能普及。
2. **续航太短**：现在主流电池续航就1-2小时，干不了啥就没电了，总不能拖着电源线走吧？得等固态电池技术突破。
3. **鲁棒性差**：实验室里好好的，换个环境（比如地毯毛长了、地板有水）就可能摔跤。我朋友的机器人在他家木地板上走得好好的，去我家瓷砖地就打滑，还得优化算法。
4. **安全问题**：万一机器人失控撞了老人小孩咋办？现在还没靠谱的安全标准。

不过趋势是好的：模块化设计（零件坏了能换）、标准化接口（不同品牌零件通用）、AI大模型加持（更聪明）。特斯拉说要2025年量产Optimus，目标价2万美元，我觉得有点乐观，但5年内家用机器人进中产家庭，应该不是梦。


## 最后说两句

看完浙大这篇综述，我最大的感受是：人形机器人不再是科幻片里的玩意儿了。从机械结构到AI大脑，每个技术模块都在快速突破。当然，现在还没到"机器人管家"的阶段，但就像10年前智能手机刚出来时谁也想不到现在的功能一样，人形机器人的爆发可能比我们想象的快。

你觉得5年后家里会有机器人帮忙做饭、打扫卫生吗？反正我挺期待的——到时候我就能彻底告别洗碗了！（前提是它别把我珍藏的碗摔了）

论文原文链接：https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008（感兴趣的技术党可以自己去啃，友情提示：有点厚，我花了3天才看完）