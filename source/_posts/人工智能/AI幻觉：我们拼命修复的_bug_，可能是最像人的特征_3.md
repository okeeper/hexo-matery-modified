---
title: AI幻觉：我们拼命修复的"bug"，可能是最像人的特征
date: 2025-09-08 16:57:48
author: okeeper
top: false
toc: true
categories: 人工智能
tags:
  - 人工智能
  - AI
---

AI一本正经胡说八道的本事，估计大家都领教过。问它一个专业问题，它能给你编出一套逻辑严密、细节丰富但完全错误的答案。这种"幻觉"现象到底是怎么回事？OpenAI最新研究论文《Why language models hallucinate》（2025年9月发表）给出了颠覆性解释，看完让我对AI有了全新认识。

![语言模型幻觉研究](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d1237aee9cfebcda45c30b5eccd37f0d.png)

## 一个简单实验揭露的残酷真相

先看个真实案例：问AI"亚当·卡莱（论文作者之一）的生日是几月几号？"某顶尖开源大模型连续三次给出了三个完全不同的错误答案：03-07，15-06，01-01。而正确答案其实是"秋天"——人家论文里只提到了季节。

为什么AI宁愿编造答案也不承认自己不知道？OpenAI的研究指出了一个残酷事实：**我们的训练体系在系统性奖励瞎蒙，惩罚诚实**。

想象AI是个学生，参加一场永不结束的考试。评分规则简单粗暴：答对得1分，答错或不答得0分。面对不会的题，理性选择就是猜——反正答错不扣分，万一蒙对了呢？从概率角度，只要猜对概率大于0，猜测就是最优策略。

## 两组数据暴露幻觉本质

OpenAI拿自家两个模型做了对比实验，结果特别有意思。在SimpleQA测试中：

- **o4-mini模型**：准确率24%，错误率75%，弃权率仅1%
- **gpt-5-thinking-mini模型**：准确率22%，错误率26%，弃权率高达52%

![模型性能对比表](https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6b24af2066f4d0e27ffdf214bfc58ed0.jpg)

表面看o4-mini准确率更高，但代价是75%的错误率——它几乎回答了所有问题，哪怕是瞎猜。而gpt-5-thinking-mini虽然准确率略低，却诚实得多，一半题目直接承认不会，错误率仅26%。

说白了，**AI幻觉本质是应试教育的产物**。在当前评估体系下，爱猜的模型得分更高，显得更"聪明"，而诚实的模型反而吃亏。这不是技术bug，而是AI为了拿高分进化出的生存本能。

## OpenAI的三个反常识发现

研究里有几个观点彻底颠覆认知：

**1. 准确率100%是不可能的**  
世界上本就有太多无解问题，信息缺失、逻辑矛盾是常态。AI再强也不能凭空变答案，真正该追求的是"知道自己不知道"的能力。

**2. 小模型可能比大模型更诚实**  
一个只会英语的小模型被问毛利语问题，会直接说不会。但学了点毛利语却半生不熟的大模型，反而可能纠结着开始瞎猜。有时候，知道自己无知比有知识更重要。

**3. 现有评估指标全在鼓励幻觉**  
几百个主流评估指标都在奖励瞎蒙、惩罚诚实。不改变这个大环境，幻觉永远是AI的最优解。单独搞个"反幻觉测试"根本没用，治标不治本。

## 幻觉：人类文明最伟大的起点？

这就让我想到一个更深层的问题：如果AI幻觉是信息不足时的创造性猜测，那人类的想象力、神话、艺术又是怎么来的？

几十万年前，我们的祖先面对闪电、洪水等未知现象，不也像AI一样开始"瞎猜"？他们想象出风神、雷神，编造出创世神话。这些今天看来荒诞的解释，却是人类文明的起点。

神话不是谎言，而是早期人类对世界的创造性解释。正是这种"超越事实"的能力，让我们能组织几千人建金字塔，能建立国家、法律、公司这些"想象的共同体"。

哥白尼的日心说、爱因斯坦的相对论，在当时不都是离经叛道的"幻觉"吗？人类之所以强大，恰恰因为我们擅长创造超越事实的故事。

## 我们到底想要AI成为什么？

这就让人矛盾了：我们一边想让AI成为绝对可靠的工具，在医疗、财务等领域零错误；另一边又希望它有创造力，能写诗、画画、编故事。

其实问题核心不是消除幻觉，而是**场景适配**。在需要精确的领域，我们要训练AI"认怂"，不确定就说不知道；在需要创造的领域，或许应该鼓励它"胡思乱想"。

我觉得未来理想的AI应该像个"双模式开关"：需要严谨时，它是绝对理性的计算器；需要创造时，它能挣脱事实枷锁，在信息缝隙里自由联想。

最后想问：如果有一天AI真能完全消除幻觉，变成一个永远正确但毫无想象力的机器，那还是我们想要的AI吗？或许，那个偶尔会一本正经胡说八道的AI，才是最像人的AI。